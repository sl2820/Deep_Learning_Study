{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN_Practice.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/sl2820/Deep_Learning_Study/blob/master/RNN_Practice.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "rWP8EZx7qgm_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Sequence Classification\n"
      ]
    },
    {
      "metadata": {
        "id": "rO2hqpALyrb2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e7cd4af8-b857-4b81-8f93-352016388ea2"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.examples.tutorials.mnist.input_data as input_data\n",
        "import tensorflow.contrib.rnn as rnn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "print (\"Packages Loaded\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Packages Loaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HC7KDRnqrRKR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Get MNIST\n"
      ]
    },
    {
      "metadata": {
        "id": "VIqTPNQkrGnN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "outputId": "15b8f6d4-b83e-4593-bd8c-4d6709da321d"
      },
      "cell_type": "code",
      "source": [
        "mnist = input_data.read_data_sets(\"data/\", one_hot = True)\n",
        "trainimgs, trainlabels, testimgs, testlabels = mnist.train.images, mnist.train.labels, mnist.test.images, mnist.test.labels\n",
        "ntrain, ntest, dim, nclasses \\\n",
        "= trainimgs.shape[0], testimgs.shape[0], trainimgs.shape[1], trainlabels.shape[1]\n",
        "print(\"MNIST LOADED\")\n",
        "print (\"TF Version is: %s\" % (tf.__version__))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-2-789df9b1d255>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use urllib or similar directly.\n",
            "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting data/train-images-idx3-ubyte.gz\n",
            "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting data/train-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n",
            "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
            "Extracting data/t10k-images-idx3-ubyte.gz\n",
            "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
            "Extracting data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "MNIST LOADED\n",
            "TF Version is: 1.11.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cm7mNidWsqDe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Define Model\n",
        "LSTM 자체는 텐서플로우 것 사용, Input 과 Output에 대한 것만 Define 하면 됌."
      ]
    },
    {
      "metadata": {
        "id": "Z7OwthTDr2aB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "diminput = 28\n",
        "dimhidden = 128\n",
        "dimoutput = nclasses\n",
        "nsteps = 28\n",
        "weights = {\n",
        "    'hidden': tf.Variable(tf.random_normal([diminput, dimhidden])), #28 --> 128\n",
        "    'out': tf.Variable(tf.random_normal([dimhidden, dimoutput]))  # 128 --> 10\n",
        "}\n",
        "\n",
        "biases = {\n",
        "    'hidden': tf.Variable(tf.random_normal([dimhidden])),\n",
        "    'out': tf.Variable(tf.random_normal([dimoutput]))\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2HzTczn_sbF_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Define Function"
      ]
    },
    {
      "metadata": {
        "id": "PYCGbC_8sbEB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9a073298-1d1b-44f7-cd02-3ef4c0fccb9a"
      },
      "cell_type": "code",
      "source": [
        "def _RNN(_X, _istate,_W,_b,_nsteps,_name):\n",
        "  # 1. Permute input from [batchsize, nsteps, diminput] --> [nsteps, batchsize, diminput]\n",
        "  # Current _X = 784 dim\n",
        "  _X = tf.transpose(_X, [1,0,2])   \n",
        "  \n",
        "  # 2. Reshape input to [nsteps*batchsize, diminput]\n",
        "  _X = tf.reshape(_X, [-1, diminput])\n",
        "  \n",
        "  # 3. Input to hidden layer\n",
        "  _H = tf.matmul(_X, _W['hidden']) + _b['hidden']\n",
        "  \n",
        "  # 4. Split data to 'nsteps' chunks --> LIST\n",
        "  _Hsplit = tf.split(_H, _nsteps, axis=0)\n",
        "  # 5. Get LSTM's final output (_LSTM_O) and State (_LSTM_S)\n",
        "  with tf.variable_scope(_name):\n",
        "    # RNN <-- tf.contrib.rnn\n",
        "    lstm_cell = rnn.BasicLSTMCell(dimhidden, forget_bias=1.0, state_is_tuple=False, reuse=tf.AUTO_REUSE)\n",
        "    _LSTM_O, _LSTM_S = rnn.static_rnn(lstm_cell, _Hsplit, initial_state=_istate)\n",
        "    \n",
        "  _O = tf.matmul(_LSTM_O[-1], _W['out']) + _b['out']  #_LSTM_O[-1] --> 맨 마지막 아웃풋\n",
        "  return{\n",
        "      'X': _X, 'H': _H, 'Hsplit': _Hsplit, 'LSTM_O': _LSTM_O, 'LSTM_S': _LSTM_S, 'O': _O\n",
        "  }\n",
        "\n",
        "print(\"Function Ready\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Function Ready\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "m5Y_gFSOsbB0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Define Graph"
      ]
    },
    {
      "metadata": {
        "id": "Kw_F1pm1sa_R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "06e154d6-e6b6-4ef9-e067-b90efab7e685"
      },
      "cell_type": "code",
      "source": [
        "learning_rate = 0.001\n",
        "x = tf.placeholder(\"float\", [None, nsteps, diminput])\n",
        "istate = tf.placeholder(\"float\", [None, 2*dimhidden])\n",
        "y = tf.placeholder(\"float\", [None, dimoutput])\n",
        "myrnn = _RNN(x, istate, weights, biases, nsteps, 'basic')\n",
        "pred = myrnn['O']\n",
        "celoss = tf.nn.softmax_cross_entropy_with_logits\n",
        "cost = tf.reduce_mean(celoss(logits=pred,labels = y))\n",
        "optm = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
        "accr = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(pred,1), tf.argmax(y,1)), tf.float32))\n",
        "init = tf.global_variables_initializer()\n",
        "print (\"Network Ready\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7fad8734d550>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
            "WARNING:tensorflow:From <ipython-input-10-3ba8ad65f32b>:8: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n",
            "Network Ready\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xxnLEevvxkdO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Run"
      ]
    },
    {
      "metadata": {
        "id": "LfEcN8yBz-tQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "t_epochs = 5\n",
        "batch_size = 128\n",
        "display_step = 1\n",
        "config = tf.ConfigProto()\n",
        "config.gpu_options.allow_growth=True\n",
        "sess = tf.Session(config=config)\n",
        "sess.run(init)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yHhPZdUCz-rV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Optimization"
      ]
    },
    {
      "metadata": {
        "id": "sE3bJVm8z-mq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "73fbaf43-1fb2-42b8-e566-1a661a0febda"
      },
      "cell_type": "code",
      "source": [
        "#Optimization Starts\n",
        "for epoch in range(t_epochs):\n",
        "  avg_cost = 0.\n",
        "  total_batch = int(mnist.train.num_examples/batch_size)\n",
        "  for i in range(total_batch):\n",
        "    batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
        "    batch_xs = batch_xs.reshape((batch_size,nsteps,diminput))\n",
        "    feeds = {x: batch_xs, y: batch_ys, istate: np.zeros((batch_size, 2*dimhidden))}\n",
        "    sess.run(optm, feed_dict=feeds)\n",
        "    avg_cost += sess.run(cost, feed_dict= feeds)/total_batch\n",
        "    \n",
        "  if epoch % display_step ==0:\n",
        "    print (\"Epoch: %03d/%03d Cost: %.9f\" % (epoch+1, t_epochs, avg_cost))\n",
        "    feeds = {x: batch_xs, y: batch_ys, istate: np.zeros((batch_size, 2*dimhidden))}\n",
        "    train_acc = sess.run(accr, feed_dict=feeds)\n",
        "    print(\"Train Accuracy: %.3f\" %(train_acc))\n",
        "    testimgs = testimgs.reshape((ntest,nsteps,diminput))\n",
        "    feeds = {x: testimgs, y: testlabels, istate: np.zeros((ntest, 2*dimhidden))}\n",
        "    test_acc = sess.run(accr,feed_dict = feeds)\n",
        "    print(\"Test Accuracy: %.3f\" % (test_acc))\n",
        "\n",
        "print(\"Optimization Done\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 001/005 Cost: 0.021602890\n",
            "Train Accuracy: 0.992\n",
            "Test Accuracy: 0.980\n",
            "Epoch: 002/005 Cost: 0.016210595\n",
            "Train Accuracy: 0.992\n",
            "Test Accuracy: 0.981\n",
            "Epoch: 003/005 Cost: 0.016350848\n",
            "Train Accuracy: 1.000\n",
            "Test Accuracy: 0.982\n",
            "Epoch: 004/005 Cost: 0.015117944\n",
            "Train Accuracy: 1.000\n",
            "Test Accuracy: 0.983\n",
            "Epoch: 005/005 Cost: 0.013567779\n",
            "Train Accuracy: 1.000\n",
            "Test Accuracy: 0.982\n",
            "Optimization Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JHtlZfgu3zMy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        " *여기까지가 RNN 8:27까지 한것  (10/9)* "
      ]
    },
    {
      "metadata": {
        "id": "phtc7T-n1kaE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### What if we use smaller number of Sequences?"
      ]
    },
    {
      "metadata": {
        "id": "GVxX7YoQ37H-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "61c8d086-228e-4023-e9d2-83de985dd24e"
      },
      "cell_type": "code",
      "source": [
        "#( Providing only the early [24,25,26,27]개 images로만) 학습할 경우\n",
        "for _nsteps in [24,25,26,27,28]:\n",
        "  # Test with truncated Sequences\n",
        "  testimgs = testimgs.reshape((ntest,nsteps,diminput))\n",
        "  testimgs_truncated = np.zeros(testimgs.shape)\n",
        "  testimgs_truncated[:,28-_nsteps:] = testimgs[:, :_nsteps,:] \n",
        "  feeds = {x: testimgs_truncated, y: testlabels, istate: np.zeros((ntest, 2*dimhidden))}\n",
        "  test_acc = sess.run(accr, feed_dict=feeds)\n",
        "  print (\"With [%d] Sequences, Test Accuracy is [%.3f]\" % (_nsteps, test_acc)) "
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "With [24] Sequences, Test Accuracy is [0.758]\n",
            "With [25] Sequences, Test Accuracy is [0.876]\n",
            "With [26] Sequences, Test Accuracy is [0.957]\n",
            "With [27] Sequences, Test Accuracy is [0.979]\n",
            "With [28] Sequences, Test Accuracy is [0.982]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "oAjkQIMOnJPP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# What is Happening Inside the RNN\n",
        "Step by step demonstration\n"
      ]
    },
    {
      "metadata": {
        "id": "DVvfIXNunW7H",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 1. Inputes to the RNN"
      ]
    },
    {
      "metadata": {
        "id": "VJodFq43nW49",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "568b22b3-fd67-4786-e1e5-1b5aba273e08"
      },
      "cell_type": "code",
      "source": [
        "# Size of Initial Inputs (기본 MNIST)\n",
        "batch_size = 5\n",
        "xtest, _ = mnist.test.next_batch(batch_size)\n",
        "print (\"Shape of 'xtest' is %s\" %(xtest.shape,))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of 'xtest' is (5, 784)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gDFe9G92qEEl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 2. Reshaped Inputs"
      ]
    },
    {
      "metadata": {
        "id": "sDPynwVGnW3G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "4c81082c-4c6e-4ce8-cfe1-45fd9f84769a"
      },
      "cell_type": "code",
      "source": [
        "# We create into 28*28 with 5 channels\n",
        "xtest_reshape = xtest.reshape((batch_size, nsteps, diminput))\n",
        "print (\"Batch size is: [%d]\" % (batch_size))\n",
        "print (\"Shape of 'xtest_reshape' is %s\" % (xtest_reshape.shape,))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Batch size is: [5]\n",
            "Shape of 'xtest_reshape' is (5, 28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FtbYZCMonW0I",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 3. Feeds"
      ]
    },
    {
      "metadata": {
        "id": "4n2l-TlDqJl4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "feeds = {x: xtest_reshape, istate: np.zeros((batch_size, 2*dimhidden))}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qo1BDxOCqJiO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 4. Individual Input to the LSTM"
      ]
    },
    {
      "metadata": {
        "id": "I5NucpnHqJeW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8b5409ac-4e3a-4996-c466-e77ab590d1a0"
      },
      "cell_type": "code",
      "source": [
        "# Size that going into LSTM [5*28, 28] --> 5개의 Data가 있고, 각각 5개의 데이터가 28개의 Sequence가 있다\n",
        "# 그리고 각 1개의 데이터 Dimension이 28\n",
        "rnnoutput_X = sess.run(myrnn['X'], feed_dict=feeds)\n",
        "print (\"Shape of 'rnnoutput_X' is %s\" % (rnnoutput_X.shape,))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of 'rnnoutput_X' is (140, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bsLXCwXXswTI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 5. Intermediate State"
      ]
    },
    {
      "metadata": {
        "id": "uOX5EzUiswQ0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ca7a45b0-0092-4998-8e24-7f13a931d66a"
      },
      "cell_type": "code",
      "source": [
        "# Size at the Hidden Layer 각 데이터 Dimension을 28 --> 128 확장\n",
        "rnnoutput_H = sess.run(myrnn['H'], feed_dict=feeds)\n",
        "print (\"Shape of 'rnnoutput_H' is %s\" % (rnnoutput_H.shape,))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of 'rnnoutput_H' is (140, 128)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "__tHGnbVswL2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 6. Actual Input to LSTM (LIST)"
      ]
    },
    {
      "metadata": {
        "id": "Ay75FHgEqJao",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "b02fd38e-bab2-4b10-8202-e32447bbf73c"
      },
      "cell_type": "code",
      "source": [
        "# Hsplit을 이용해서 140을 28로 만들어 리스트가 됨. 리스트안에 각각의 아이템은 5*128\n",
        "rnnoutput_Hsplit = sess.run(myrnn['Hsplit'], feed_dict=feeds)\n",
        "print (\"Type of 'rnnoutput_Hsplit' is %s\" % (type(rnnoutput_Hsplit)))\n",
        "print (\"Length of 'rnnoutput_Hsplit' is %s and the shape of each item is %s\"\n",
        "      % (len(rnnoutput_Hsplit), rnnoutput_Hsplit[0].shape))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Type of 'rnnoutput_Hsplit' is <class 'list'>\n",
            "Length of 'rnnoutput_Hsplit' is 28 and the shape of each item is (5, 128)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jgNe_TEhnWxo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Output from the LSTM (LIST)"
      ]
    },
    {
      "metadata": {
        "id": "-QcoKTnKupq2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "5fb70736-7953-4778-e64a-2618450943e5"
      },
      "cell_type": "code",
      "source": [
        "# 들어간 사이즈와 동일하게 Out / 28개의 Output으로, 각각 5*128\n",
        "rnnoutput_LSTM_O = sess.run(myrnn['LSTM_O'], feed_dict=feeds)\n",
        "print (\"Type of 'rnnoutput_LSTM_O' is %s\" % (type(rnnoutput_LSTM_O)))\n",
        "print (\"Length of 'rnnoutput_LSTM_O' is %s and the shape of each item is %s\"\n",
        "      % (len(rnnoutput_LSTM_O), rnnoutput_LSTM_O[0].shape))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Type of 'rnnoutput_LSTM_O' is <class 'list'>\n",
            "Length of 'rnnoutput_LSTM_O' is 28 and the shape of each item is (5, 128)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uhUj4MbMupof",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Final Prediction"
      ]
    },
    {
      "metadata": {
        "id": "ik90fjaKupmN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8089f862-a715-4013-c93d-3e47d11695b9"
      },
      "cell_type": "code",
      "source": [
        "# 5개의 아이템에 대해서 10개의 클래스로\n",
        "rnnoutput_O = sess.run(myrnn['O'], feed_dict=feeds)\n",
        "print (\"Shapeof rnnoutput_O is %s\" % (rnnoutput_O.shape,))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shapeof rnnoutput_O is (5, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0VZROO4Lupj2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6mc4lwA3upga",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}