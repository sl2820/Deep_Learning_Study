{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN_Practice.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/sl2820/Deep_Learning_Study/blob/master/RNN_Practice.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "rWP8EZx7qgm_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Sequence Classification\n"
      ]
    },
    {
      "metadata": {
        "id": "rO2hqpALyrb2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "38a5476c-51d6-40ee-a99c-c219083feff2"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.examples.tutorials.mnist.input_data as input_data\n",
        "import tensorflow.contrib.rnn as rnn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "print (\"Packages Loaded\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Packages Loaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HC7KDRnqrRKR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Get MNIST\n"
      ]
    },
    {
      "metadata": {
        "id": "VIqTPNQkrGnN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "592f0848-a123-4270-a918-1d7668364f55"
      },
      "cell_type": "code",
      "source": [
        "mnist = input_data.read_data_sets(\"data/\", one_hot = True)\n",
        "trainimgs, trainlabels, testimgs, testlabels = mnist.train.images, mnist.train.labels, mnist.test.images, mnist.test.labels\n",
        "ntrain, ntest, dim, nclasses \\\n",
        "= trainimgs.shape[0], testimgs.shape[0], trainimgs.shape[1], trainlabels.shape[1]\n",
        "print(\"MNIST LOADED\")\n",
        "print (\"TF Version is: %s\" % (tf.__version__))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting data/train-images-idx3-ubyte.gz\n",
            "Extracting data/train-labels-idx1-ubyte.gz\n",
            "Extracting data/t10k-images-idx3-ubyte.gz\n",
            "Extracting data/t10k-labels-idx1-ubyte.gz\n",
            "MNIST LOADED\n",
            "TF Version is: 1.11.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cm7mNidWsqDe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Define Model\n",
        "LSTM 자체는 텐서플로우 것 사용, Input 과 Output에 대한 것만 Define 하면 됌."
      ]
    },
    {
      "metadata": {
        "id": "Z7OwthTDr2aB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "diminput = 28\n",
        "dimhidden = 128\n",
        "dimoutput = nclasses\n",
        "nsteps = 28\n",
        "weights = {\n",
        "    'hidden': tf.Variable(tf.random_normal([diminput, dimhidden])), #28 --> 128\n",
        "    'out': tf.Variable(tf.random_normal([dimhidden, dimoutput]))  # 128 --> 10\n",
        "}\n",
        "\n",
        "biases = {\n",
        "    'hidden': tf.Variable(tf.random_normal([dimhidden])),\n",
        "    'out': tf.Variable(tf.random_normal([dimoutput]))\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2HzTczn_sbF_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Define Function"
      ]
    },
    {
      "metadata": {
        "id": "PYCGbC_8sbEB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e08095f7-8948-494f-caa4-34eaa1c67d7a"
      },
      "cell_type": "code",
      "source": [
        "def _RNN(_X, _istate,_W,_b,_nsteps,_name):\n",
        "  # 1. Permute input from [batchsize, nsteps, diminput] --> [nsteps, batchsize, diminput]\n",
        "  # Current _X = 784 dim\n",
        "  _X = tf.transpose(_X, [1,0,2])   \n",
        "  \n",
        "  # 2. Reshape input to [nsteps*batchsize, diminput]\n",
        "  _X = tf.reshape(_X, [-1, diminput])\n",
        "  \n",
        "  # 3. Input to hidden layer\n",
        "  _H = tf.matmul(_X, _W['hidden']) + _b['hidden']\n",
        "  \n",
        "  # 4. Split data to 'nsteps' chunks --> LIST\n",
        "  _Hsplit = tf.split(_H, _nsteps, axis=0)\n",
        "  # 5. Get LSTM's final output (_LSTM_O) and State (_LSTM_S)\n",
        "  with tf.variable_scope(_name):\n",
        "    # RNN <-- tf.contrib.rnn\n",
        "    lstm_cell = rnn.BasicLSTMCell(dimhidden, forget_bias=1.0, state_is_tuple=False, reuse=True)\n",
        "    _LSTM_O, _LSTM_S = rnn.static_rnn(lstm_cell, _Hsplit, initial_state=_istate)\n",
        "    \n",
        "  _O = tf.matmul(_LSTM_O[-1], _W['out']) + _b['out']  #_LSTM_O[-1] --> 맨 마지막 아웃풋\n",
        "  return{\n",
        "      'X': _X, 'H': _H, 'Hsplit': _Hsplit, 'LSTM_O': _LSTM_O, 'LSTM_S': _LSTM_S, 'O': _O\n",
        "  }\n",
        "\n",
        "print(\"Function Ready\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Function Ready\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "m5Y_gFSOsbB0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Define Graph"
      ]
    },
    {
      "metadata": {
        "id": "Kw_F1pm1sa_R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "03432490-eae5-48c9-c279-647e02108311"
      },
      "cell_type": "code",
      "source": [
        "learning_rate = 0.001\n",
        "x = tf.placeholder(\"float\", [None, nsteps, diminput])\n",
        "istate = tf.placeholder(\"float\", [None, 2*dimhidden])\n",
        "y = tf.placeholder(\"float\", [None, dimoutput])\n",
        "myrnn = _RNN(x, istate, weights, biases, nsteps, 'basic')\n",
        "pred = myrnn['O']\n",
        "celoss = tf.nn.softmax_cross_entropy_with_logits\n",
        "cost = tf.reduce_mean(celoss(logits=pred,labels = y))\n",
        "optm = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
        "accr = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(pred,1), tf.argmax(y,1)), tf.float32))\n",
        "init = tf.global_variables_initializer()\n",
        "print (\"Network Ready\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7f7dd0fb5278>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
            "WARNING:tensorflow:From <ipython-input-17-a4bbccc271c4>:8: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n",
            "Network Ready\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xxnLEevvxkdO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Run"
      ]
    },
    {
      "metadata": {
        "id": "LfEcN8yBz-tQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "t_epochs = 5\n",
        "batch_size = 128\n",
        "display_step = 1\n",
        "config = tf.ConfigProto()\n",
        "config.gpu_options.allow_growth=True\n",
        "sess = tf.Session(config=config)\n",
        "sess.run(init)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yHhPZdUCz-rV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Optimization"
      ]
    },
    {
      "metadata": {
        "id": "sE3bJVm8z-mq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "8f7d818e-408e-4456-e090-0f22b00787f5"
      },
      "cell_type": "code",
      "source": [
        "#Optimization Starts\n",
        "for epoch in range(t_epochs):\n",
        "  avg_cost = 0.\n",
        "  total_batch = int(mnist.train.num_examples/batch_size)\n",
        "  for i in range(total_batch):\n",
        "    batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
        "    batch_xs = batch_xs.reshape((batch_size,nsteps,diminput))\n",
        "    feeds = {x: batch_xs, y: batch_ys, istate: np.zeros((batch_size, 2*dimhidden))}\n",
        "    sess.run(optm, feed_dict=feeds)\n",
        "    avg_cost += sess.run(cost, feed_dict= feeds)/total_batch\n",
        "    \n",
        "  if epoch % display_step ==0:\n",
        "    print (\"Epoch: %03d/%03d Cost: %.9f\" % (epoch, t_epochs, avg_cost))\n",
        "    feeds = {x: batch_xs, y: batch_ys, istate: np.zeros((batch_size, 2*dimhidden))}\n",
        "    train_acc = sess.run(accr, feed_dict=feeds)\n",
        "    print(\"Train Accuracy: %.3f\" %(train_acc))\n",
        "    testimgs = testimgs.reshape((ntest,nsteps,diminput))\n",
        "    feeds = {x: testimgs, y: testlabels, istate: np.zeros((ntest, 2*dimhidden))}\n",
        "    test_acc = sess.run(accr,feed_dict = feeds)\n",
        "    print(\"Test Accuracy: %.3f\" % (test_acc))\n",
        "\n",
        "print(\"Optimization Done\")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 000/005 Cost: 0.154996177\n",
            "Train Accuracy: 0.953\n",
            "Test Accuracy: 0.955\n",
            "Epoch: 001/005 Cost: 0.100688199\n",
            "Train Accuracy: 0.984\n",
            "Test Accuracy: 0.962\n",
            "Epoch: 002/005 Cost: 0.075377963\n",
            "Train Accuracy: 0.969\n",
            "Test Accuracy: 0.961\n",
            "Epoch: 003/005 Cost: 0.059422904\n",
            "Train Accuracy: 0.992\n",
            "Test Accuracy: 0.973\n",
            "Epoch: 004/005 Cost: 0.047436275\n",
            "Train Accuracy: 0.984\n",
            "Test Accuracy: 0.979\n",
            "Optimization Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JHtlZfgu3zMy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "여기까지가 RNN 8:27까지 한것 "
      ]
    },
    {
      "metadata": {
        "id": "phtc7T-n1kaE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### What if we use smaller number of Sequences?\n",
        "내일 해보기"
      ]
    },
    {
      "metadata": {
        "id": "GVxX7YoQ37H-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}