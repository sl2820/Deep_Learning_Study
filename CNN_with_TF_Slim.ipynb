{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN with TF-Slim",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/sl2820/Deep_Learning_Study/blob/master/CNN_with_TF_Slim.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "OJwBvW2Bnq_4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### CNN MODEL wtih TF-Slim"
      ]
    },
    {
      "metadata": {
        "id": "aOVE7oM6ZXyI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# CNN Model with TF-Slim"
      ]
    },
    {
      "metadata": {
        "id": "h3COpZ7MZWSo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ab02ceef-de3f-4199-b4ba-be94fd9a8ed3"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "from scipy import ndimage\n",
        "from six.moves import urllib\n",
        "import tensorflow.contrib.slim as slim\n",
        "import gzip\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "print (\"Current TF Version [%s]\" % (tf.__version__))\n",
        "print (\"Package Loaded\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Current TF Version [1.11.0-rc2]\n",
            "Package Loaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ADDfjinpw3N1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "###\n",
        "#def CNN (inputs, _is_training=True):\n",
        " # x = tf.reshape(inputs, [-1,28,28,1])\n",
        "  #batch_norm_params = {'is_training': _is_training, 'decay': 0.9, 'updates_collections': None}\n",
        "  #net = slim.conv2d(x, 32, [5,5], padding='SAME'\n",
        "  #                 , activation_fn = tf.nn.relu\n",
        "  #                 , weights_initializer = tf.truncated_normal_initializer(stddev = 0.01)\n",
        "  #                 , normalizer_fn = slim.batch_norm\n",
        "  #                 , normalizer_params = batch_norm_params\n",
        "  #                 , scope = 'conv1') # adding bias, normalizing and everything is done right away.\n",
        "  #net = slim.max_pool2d(net, [2,2], scope = 'pool1')\n",
        "  #net = slim.conv2d(net, 64, [5,5], scope = 'conv2')\n",
        "  #net = slim.max_pool2d(net, [2,2], scope = 'pool2')\n",
        "  #net = slim.flatten(net, scope = 'flatten3')\n",
        "  #net = slim.fully_connected(net, 1024\n",
        "  #                          , activation_fn = tf.nn.relu\n",
        "  #                          , weights_initializer = tf.truncated_normal_initializer(stddev = 0.01)\n",
        "  #                          , normalizer_fn = slim.batch_norm\n",
        "  #                          , normalizer_params = batch_norm_params\n",
        "  #                          , scope = 'fc4')\n",
        "  #net = slim.dropout(net, keep_prob = 0.7, is_training=_is_training, scope = 'dropout4')\n",
        "  #out = slim.fully_connected(net, 10, activation_fn = None, normalizer_fn = None, scope = 'fco')\n",
        "  #return out\n",
        "###"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3x1BJgwpnpPP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Handling MNIST"
      ]
    },
    {
      "metadata": {
        "id": "jRXxHNduva9v",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Data URL\n",
        "SOURCE_URL = \"http://yann.lecun.com/exdb/mnist/\"\n",
        "DATA_DIRECTORY = \"data\"\n",
        "# Parameters for MNIST\n",
        "IMAGE_SIZE = 28\n",
        "NUM_CHANNELS = 1\n",
        "PIXEL_DEPTH = 255\n",
        "NUM_LABELS = 10\n",
        "VALIDATION_SIZE = 5000 # Size of the validation set\n",
        "\n",
        "# Download MNIST data, if necessary\n",
        "def maybe_download(filename):\n",
        "  if not tf.gfile.Exists(DATA_DIRECTORY):\n",
        "    tf.gfile.MakeDirs(DATA_DIRECTORY)\n",
        "  filepath = os.path.join(DATA_DIRECTORY, filename)\n",
        "  if not tf.gfile.Exists(filepath):\n",
        "    filepath, _ = urllib.request.urlretrieve(SOURCE_URL + filename, filepath)\n",
        "    with tf.gfile.GFile(filepath) as f:\n",
        "      size = f.size()\n",
        "    print (\"Successfully downloaded \", filename, size, ' bytes.')\n",
        "  return filepath\n",
        "\n",
        "# Extract the images\n",
        "def extract_data(filename, num_images):\n",
        "    \"\"\"Extract the images into a 4D tensor [image index, y, x, channels].\n",
        "    Values are rescaled from [0, 255] down to [-0.5, 0.5].\n",
        "    \"\"\"\n",
        "    print('Extracting', filename)\n",
        "    with gzip.open(filename) as bytestream:\n",
        "        bytestream.read(16)\n",
        "        buf = bytestream.read(IMAGE_SIZE * IMAGE_SIZE * num_images * NUM_CHANNELS)\n",
        "        data = numpy.frombuffer(buf, dtype=numpy.uint8).astype(numpy.float32)\n",
        "        data = (data - (PIXEL_DEPTH / 2.0)) / PIXEL_DEPTH\n",
        "        data = data.reshape(num_images, IMAGE_SIZE, IMAGE_SIZE, NUM_CHANNELS)\n",
        "        data = numpy.reshape(data, [num_images, -1])\n",
        "    return data\n",
        "\n",
        "# Extract the Labels\n",
        "def extract_labels(filename, num_images):\n",
        "  with gzip.open(filename) as bytestream:\n",
        "    bytestream.read(8)\n",
        "    buf = bytestream.read(1*num_images)\n",
        "    labels = np.frombuffer(buf, dtype = np.uint8).astype(np.int64)\n",
        "    num_labels_data = len(labels)\n",
        "    one_hot_encoding = np.zeros((num_labels_data, NUM_LABELS))\n",
        "    one_hot_encoding[np.arange(num_labels_data), labels]=1\n",
        "    one_hot_encoding = np.reshape(one_hot_encoding, [-1, NUM_LABELS])\n",
        "  return one_hot_encoding\n",
        "\n",
        "# Augment training data\n",
        "def expend_training_data(images, labels):\n",
        "\n",
        "    expanded_images = []\n",
        "    expanded_labels = []\n",
        "\n",
        "    j = 0 # counter\n",
        "    for x, y in zip(images, labels):\n",
        "        j = j+1\n",
        "        if j%100==0:\n",
        "            print ('expanding data : %03d / %03d' % (j,numpy.size(images,0)))\n",
        "\n",
        "        # register original data\n",
        "        expanded_images.append(x)\n",
        "        expanded_labels.append(y)\n",
        "\n",
        "        # get a value for the background\n",
        "        # zero is the expected value, but median() is used to estimate background's value \n",
        "        bg_value = numpy.median(x) # this is regarded as background's value        \n",
        "        image = numpy.reshape(x, (-1, 28))\n",
        "\n",
        "        for i in range(4):\n",
        "            # rotate the image with random degree\n",
        "            angle = numpy.random.randint(-15,15,1)\n",
        "            new_img = ndimage.rotate(image,angle,reshape=False, cval=bg_value)\n",
        "\n",
        "            # shift the image with random distance\n",
        "            shift = numpy.random.randint(-2, 2, 2)\n",
        "            new_img_ = ndimage.shift(new_img,shift, cval=bg_value)\n",
        "\n",
        "            # register new training data\n",
        "            expanded_images.append(numpy.reshape(new_img_, 784))\n",
        "            expanded_labels.append(y)\n",
        "\n",
        "    # images and labels are concatenated for random-shuffle at each epoch\n",
        "    # notice that pair of image and label should not be broken\n",
        "    expanded_train_total_data = numpy.concatenate((expanded_images, expanded_labels), axis=1)\n",
        "    numpy.random.shuffle(expanded_train_total_data)\n",
        "\n",
        "    return expanded_train_total_data\n",
        "\n",
        "# Prepare MNISt data\n",
        "def prepare_MNIST_data(use_data_augmentation=True):\n",
        "    # Get the data.\n",
        "    train_data_filename = maybe_download('train-images-idx3-ubyte.gz')\n",
        "    train_labels_filename = maybe_download('train-labels-idx1-ubyte.gz')\n",
        "    test_data_filename = maybe_download('t10k-images-idx3-ubyte.gz')\n",
        "    test_labels_filename = maybe_download('t10k-labels-idx1-ubyte.gz')\n",
        "\n",
        "    # Extract it into numpy arrays.\n",
        "    train_data = extract_data(train_data_filename, 60000)\n",
        "    train_labels = extract_labels(train_labels_filename, 60000)\n",
        "    test_data = extract_data(test_data_filename, 10000)\n",
        "    test_labels = extract_labels(test_labels_filename, 10000)\n",
        "\n",
        "    # Generate a validation set.\n",
        "    validation_data = train_data[:VALIDATION_SIZE, :]\n",
        "    validation_labels = train_labels[:VALIDATION_SIZE,:]\n",
        "    train_data = train_data[VALIDATION_SIZE:, :]\n",
        "    train_labels = train_labels[VALIDATION_SIZE:,:]\n",
        "\n",
        "    # Concatenate train_data & train_labels for random shuffle\n",
        "    if use_data_augmentation:\n",
        "        train_total_data = expend_training_data(train_data, train_labels)\n",
        "    else:\n",
        "        train_total_data = numpy.concatenate((train_data, train_labels), axis=1)\n",
        "\n",
        "    train_size = train_total_data.shape[0]\n",
        "\n",
        "    return train_total_data, train_size, validation_data, validation_labels, test_data, test_labels\n",
        "\n",
        "#### From github.com/Hwalsuklee/tensorflow-mnist-cnn\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bLAHRVjrvco0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### For Our Model"
      ]
    },
    {
      "metadata": {
        "id": "ssDm9Zeav8-n",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Load MNIST\n"
      ]
    },
    {
      "metadata": {
        "id": "AUHudFdmvXmf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "outputId": "33c46503-6205-4965-d1e3-c53bcd57d1d3"
      },
      "cell_type": "code",
      "source": [
        "mnist = input_data.read_data_sets('data/', one_hot = True)\n",
        "trainimg = mnist.train.images\n",
        "trainlabel = mnist.train.labels\n",
        "valimg = mnist.validation.images\n",
        "vallabel = mnist.validation.labels\n",
        "testimg = mnist.test.images\n",
        "testlabel = mnist.test.labels\n",
        "print (\"MNIST Ready\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-4-17386699911b>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use urllib or similar directly.\n",
            "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting data/train-images-idx3-ubyte.gz\n",
            "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting data/train-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n",
            "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
            "Extracting data/t10k-images-idx3-ubyte.gz\n",
            "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
            "Extracting data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "MNIST Ready\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RdIjhHsfxs3c",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Define Model"
      ]
    },
    {
      "metadata": {
        "id": "YF0-U6LWwAR7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f70d6bb2-d850-4a1e-d683-4e1af4b709e6"
      },
      "cell_type": "code",
      "source": [
        "n_input = 784\n",
        "n_classes = 10\n",
        "x = tf.placeholder(\"float\", [None, n_input])\n",
        "y = tf.placeholder(\"float\", [None, n_classes])\n",
        "is_training = tf.placeholder(tf.bool)\n",
        "\n",
        "def lrelu(x, leak=0.2, name='lrelu'):\n",
        "    with tf.variable_scope(name):\n",
        "        f1 = 0.5 * (1 + leak)\n",
        "        f2 = 0.5 * (1 - leak)\n",
        "        return f1 * x + f2 * abs(x)\n",
        "\n",
        "def CNN(inputs, is_training=True):\n",
        "    x = tf.reshape(inputs, [-1, 28, 28, 1])\n",
        "    batch_norm_params = {'is_training': is_training\n",
        "                         , 'decay':0.9\n",
        "                         , 'updates_collections':None}\n",
        "    init_func = tf.truncated_normal_initializer(stddev=0.01)\n",
        "    net = slim.conv2d(x, 32, [5, 5], padding='SAME'\n",
        "                                , activation_fn = lrelu\n",
        "                                , weights_initializer = init_func\n",
        "                                , normalizer_fn = slim.batch_norm\n",
        "                                , normalizer_params = batch_norm_params\n",
        "                                , scope='conv1')\n",
        "    net = slim.max_pool2d(net, [2, 2], scope='pooll')\n",
        "    net = slim.conv2d(x, 64, [5, 5], padding='SAME'\n",
        "                                , activation_fn = lrelu\n",
        "                                , weights_initializer = init_func\n",
        "                                , normalizer_fn = slim.batch_norm\n",
        "                                , normalizer_params = batch_norm_params\n",
        "                                , scope='conv2')\n",
        "    net = slim.max_pool2d(net, [2, 2], scope='pool2')\n",
        "    net = slim.flatten(net, scope='flatten3')\n",
        "    net = slim.fully_connected(net, 1024\n",
        "                                , activation_fn = lrelu\n",
        "                                , weights_initializer = init_func\n",
        "                                , normalizer_fn = slim.batch_norm\n",
        "                                , normalizer_params = batch_norm_params\n",
        "                                , scope='fc4')\n",
        "    net = slim.dropout(net, keep_prob=0.7, is_training=is_training, scope='dr')\n",
        "    out = slim.fully_connected(net, n_classes, activation_fn=None, normalizer_fn=None, scope='foo')\n",
        "    return out\n",
        "print (\"NETWORK READY\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NETWORK READY\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4q9mduAjv_YJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Define Graph"
      ]
    },
    {
      "metadata": {
        "id": "g3oaFzuPv8HV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "ae32aeff-559d-4958-a6e2-2b7caf2734fd"
      },
      "cell_type": "code",
      "source": [
        "# PREDICTION\n",
        "pred = CNN(x, is_training)\n",
        "\n",
        "# LOSS AND OPTIMIZER\n",
        "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=pred))\n",
        "optm = tf.train.AdamOptimizer(learning_rate=0.001).minimize(cost)\n",
        "corr = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
        "accr = tf.reduce_mean(tf.cast(corr, \"float\"))\n",
        "\n",
        "# INITIALIZER\n",
        "init = tf.global_variables_initializer()\n",
        "sess = tf.Session()\n",
        "sess.run(init)\n",
        "print (\"FUNCTION READY\")\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-6-0840b406d908>:4: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n",
            "FUNCTION READY\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "opGSdz9RvjqA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Check Variables"
      ]
    },
    {
      "metadata": {
        "id": "rMBWDwrvvYDb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "d05763d7-4848-44b4-f72d-8c6b0cca50ef"
      },
      "cell_type": "code",
      "source": [
        "print(\"================== Trainable Variables=====================\")\n",
        "t_weights = tf.trainable_variables()\n",
        "var_names_list = [v.name for v in tf.trainable_variables()]\n",
        "for i in range (len(t_weights)):\n",
        "  wval = sess.run(t_weights[i])\n",
        "  print (\"[%d/%d] [%s] / SHAPE IS %s\"\n",
        "        % (i, len(t_weights), var_names_list[i], wval.shape,))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "================== Trainable Variables=====================\n",
            "[0/8] [conv1/weights:0] / SHAPE IS (5, 5, 1, 32)\n",
            "[1/8] [conv1/BatchNorm/beta:0] / SHAPE IS (32,)\n",
            "[2/8] [conv2/weights:0] / SHAPE IS (5, 5, 1, 64)\n",
            "[3/8] [conv2/BatchNorm/beta:0] / SHAPE IS (64,)\n",
            "[4/8] [fc4/weights:0] / SHAPE IS (12544, 1024)\n",
            "[5/8] [fc4/BatchNorm/beta:0] / SHAPE IS (1024,)\n",
            "[6/8] [foo/weights:0] / SHAPE IS (1024, 10)\n",
            "[7/8] [foo/biases:0] / SHAPE IS (10,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "anu0hh5wvSWj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Saver"
      ]
    },
    {
      "metadata": {
        "id": "j2fFRkgc1STM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c20be4f6-21e5-4714-8127-c7601855ef4f"
      },
      "cell_type": "code",
      "source": [
        "savedir = 'nets/cnn_mnist_modern'\n",
        "saver = tf.train.Saver(max_to_keep = 100)\n",
        "save_step = 4\n",
        "if not os.path.exists(savedir):\n",
        "  os.makedirs(savedir)\n",
        "print (\"Saver Ready\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saver Ready\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "N1rmKVI91Sg-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Augmentation of DATA"
      ]
    },
    {
      "metadata": {
        "id": "dzVM01Ro1SeE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def augment_img(xs):\n",
        "  out = np.copy(xs)\n",
        "  xs_r = np.reshape(xs, [-1,28,28])\n",
        "  for i in range (xs_r.shape[0]):\n",
        "    xs_img = xs_r[i, :, :]\n",
        "    bg_value = 0\n",
        "    # Rotate\n",
        "    angle = np.random.randint(-15,15,1).astype(float)\n",
        "    xs_img = ndimage.rotate(xs_img, angle, reshape=False, cval = bg_value)\n",
        "    #Zoom\n",
        "    rg = 0.1\n",
        "    zoom_factor = np.random.uniform(1.,1.+rg)\n",
        "    h, w = xs_img.shape[:2]\n",
        "    zh = int(np.round(zoom_factor * h))\n",
        "    zw = int(np.round(zoom_factor * w))\n",
        "    top = (zh-h)//2\n",
        "    left = (zw-w)//2\n",
        "    zoom_tuple = (zoom_factor,) *2 + (1,) * (xs_img.ndim-2)\n",
        "    temp = ndimage.zoom(xs_img[top:top+zh, left: left+zw], zoom_tuple)\n",
        "    trim_top = ((temp.shape[0]-h)//2)\n",
        "    trim_left = ((temp.shape[1]-w)//2)\n",
        "    xs_img = temp[trim_top:trim_top+h, trim_left: trim_left+w]\n",
        "    #Shift\n",
        "    shift = np.random.randint(-3,3,2)\n",
        "    xs_img = ndimage.shift(xs_img, shift, cval=bg_value)\n",
        "    # Reshape\n",
        "    xs_v = np.reshape(xs_img, [1,-1])\n",
        "    out [i, : ] = xs_v\n",
        "  return out\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ORgfVGDW1Scy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Test Augmentation"
      ]
    },
    {
      "metadata": {
        "id": "60KjhZz21SY3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 585
        },
        "outputId": "a6b525e9-37d2-4d63-f028-7a54a0a49385"
      },
      "cell_type": "code",
      "source": [
        "naug = 2\n",
        "batch_xs = trainimg[:naug, :]\n",
        "xs2 = augment_img(batch_xs)\n",
        "for i in range (naug):\n",
        "  x1 = batch_xs[i,:].reshape([28,28])\n",
        "  x2 = xs2[i,:].reshape([28,28])\n",
        "  f, (ax1, ax2) = plt.subplots(1,2,sharey=True, figsize = (9,4))\n",
        "  ax1.matshow(x1, vmin=0, vmax = 1, cmap = plt.cm.gray)\n",
        "  ax1.set_title(\"Original\")\n",
        "  ax2.matshow(x2, vmin=0, vmax = 1, cmap = plt.cm.gray)\n",
        "  ax2.set_title(\"Transformed\")\n",
        "  plt.show()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/scipy/ndimage/interpolation.py:600: UserWarning: From scipy 0.13.0, the output shape of zoom() is calculated with round() instead of int() - for these inputs the size of the returned array has changed.\n",
            "  \"the returned array has changed.\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhYAAAEBCAYAAAAkfOxtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQDQUFgAAIBoKCwAAEA2FBQAAiOb/AzpsKMJoWKYQAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f5af9445c18>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhYAAAEBCAYAAAAkfOxtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n7mQxiwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f5ad32ebda0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "W3WsCqY2rk_u",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### RUN"
      ]
    },
    {
      "metadata": {
        "id": "2419QgML4VxM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "outputId": "cbf039fa-deda-4b89-a6ea-8fa0c8bd7a32"
      },
      "cell_type": "code",
      "source": [
        "# pARAMETERS\n",
        "training_epochs = 20\n",
        "batch_size = 256\n",
        "display_step = 4\n",
        "val_acc = 0\n",
        "val_acc_max = 0\n",
        "\n",
        "#Optimize\n",
        "\n",
        "for epoch in range(training_epochs):\n",
        "  avg_cost = 0\n",
        "  total_batch = int(mnist.train.num_examples/batch_size)\n",
        "  # Iteration\n",
        "  for i in range (total_batch):\n",
        "    batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
        "    #Augment Data\n",
        "    if np.random.rand()<0.2:\n",
        "      batch_x = augment_img(batch_x)\n",
        "    feeds = {x: batch_x, y: batch_y, is_training: True}\n",
        "    sess.run(optm, feed_dict=feeds)\n",
        "    avg_cost += sess.run(cost, feed_dict = feeds)\n",
        "  avg_cost = avg_cost / total_batch\n",
        "  \n",
        "  # Display\n",
        "  if (epoch+1)%display_step ==0:\n",
        "    print (\"Epoch: %03d/%03d Cost: %.9f\" % (epoch+1, training_epochs, avg_cost))\n",
        "    randidx = np.random.permutation(trainimg.shape[0])[:500]\n",
        "    feeds = {x:trainimg[randidx], y: trainlabel[randidx], is_training: False}\n",
        "    train_acc = sess.run(accr, feed_dict = feeds)\n",
        "    print (\"Train Accuracy: %.5f\" % (train_acc))\n",
        "    feeds = {x: valimg, y: vallabel, is_training: False}\n",
        "    val_acc = sess.run(accr, feed_dict = feeds)\n",
        "    print(\"Validation Accuracy: %.5f\" %(val_acc))\n",
        "  \n",
        "  # Save\n",
        "  if (epoch+1)%save_step == 0:\n",
        "    savename = savedir + \"net-\" +str(epoch)+\".ckpt\"\n",
        "    saver.save(sess=sess, save_path = savename)\n",
        "    print (\" [%s] SAVED.\" % savename)\n",
        "  \n",
        "  # Maximum Validation Accuracy\n",
        "  if val_acc>val_acc_max:\n",
        "    val_acc_max = val_acc\n",
        "    best_epoch = epoch\n",
        "    print (\"\\x1b[31m BEST EPOCH UPDATED!! [%d] \\x1b[0m\" % (best_epoch))\n",
        "print (\"Optimization Finished\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/scipy/ndimage/interpolation.py:600: UserWarning: From scipy 0.13.0, the output shape of zoom() is calculated with round() instead of int() - for these inputs the size of the returned array has changed.\n",
            "  \"the returned array has changed.\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 004/020 Cost: 0.051506778\n",
            "Train Accuracy: 0.99400\n",
            "Validation Accuracy: 0.98840\n",
            " [nets/cnn_mnist_modernnet-3.ckpt] SAVED.\n",
            "\u001b[31m BEST EPOCH UPDATED!! [3] \u001b[0m\n",
            "Epoch: 008/020 Cost: 0.032999793\n",
            "Train Accuracy: 0.99800\n",
            "Validation Accuracy: 0.98880\n",
            " [nets/cnn_mnist_modernnet-7.ckpt] SAVED.\n",
            "\u001b[31m BEST EPOCH UPDATED!! [7] \u001b[0m\n",
            "Epoch: 012/020 Cost: 0.024630571\n",
            "Train Accuracy: 1.00000\n",
            "Validation Accuracy: 0.99020\n",
            " [nets/cnn_mnist_modernnet-11.ckpt] SAVED.\n",
            "\u001b[31m BEST EPOCH UPDATED!! [11] \u001b[0m\n",
            "Epoch: 016/020 Cost: 0.022990071\n",
            "Train Accuracy: 0.99800\n",
            "Validation Accuracy: 0.99080\n",
            " [nets/cnn_mnist_modernnet-15.ckpt] SAVED.\n",
            "\u001b[31m BEST EPOCH UPDATED!! [15] \u001b[0m\n",
            "Epoch: 020/020 Cost: 0.022233902\n",
            "Train Accuracy: 0.99800\n",
            "Validation Accuracy: 0.98740\n",
            " [nets/cnn_mnist_modernnet-19.ckpt] SAVED.\n",
            "Optimization Finished\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EX_IhiVE7LKC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Compute Test Accuracy"
      ]
    },
    {
      "metadata": {
        "id": "hxZuLsWX7g7b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "131c4ef7-38e8-422f-b073-c1b10677f792"
      },
      "cell_type": "code",
      "source": [
        "best_epoch = 15\n",
        "restorename = savedir + \"net-\" +str(best_epoch)+\".ckpt\"\n",
        "print (\"Loading [%s]\" % (restorename))\n",
        "saver.restore(sess, restorename)\n",
        "feeds = {x:testimg, y: testlabel, is_training: False}\n",
        "test_acc = sess.run(accr, feed_dict = feeds)\n",
        "print (\"Test Accuracy: %.5f\" % (test_acc))\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading [nets/cnn_mnist_modernnet-15.ckpt]\n",
            "INFO:tensorflow:Restoring parameters from nets/cnn_mnist_modernnet-15.ckpt\n",
            "Test Accuracy: 0.98990\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fp2SIv9s81-k",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}